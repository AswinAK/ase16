

[home](http://tiny.cc/ase2016) |
[copyright](https://github.com/txt/ase16/blob/master/LICENSE.md) &copy;2016, tim&commat;menzies.us
<br>
[<img width=900 src="https://raw.githubusercontent.com/txt/ase16/master/img/mase16.png">](http://tiny.cc/ase2016)<br>
[overview](https://github.com/txt/ase16/blob/master/doc/overview.md) |
[syllabus](https://github.com/txt/ase16/blob/master/doc/syllabus.md) |
[src](https://github.com/txt/ase16/tree/master/src) |
[submit](http://tiny.cc/ase16give) |
[chat](https://ase16.slack.com/) 


______

# Homework789: November project as homeworks

30 marks

8,8,8 for generating the reports for hoemworks 7,8,9

6 marks for a presentation on last homework to the class


## What to Hand in

For each of the following tasks, create a sub-directory called
CODE7, CODE8, CODE9 that includes:

+ All related python code
+ A README.md file containing your report.
+ Sub-directories CODEx/img for images; CODEx/data for data.

Using some URL shortener (e.g. goo.gl), shorten the URL to `hw/code/x`
and paste into the usual submission page.


## What to do

For each of the following,  write a Markdown readme.md file (1500 words+)
Note that there will be some overlap in the content
of these reports. Feel free to "borrow" text from
your earlier reports for your later reports-- ideally, improving the borrowed bits each time.

Your report must

+ Explain all algorithms it discussed (so I know that you know what is going on in them)
+ Succinctly describe the results. Not 1000 tables, but key insights relating to a small number of key displayed
  results
    + No figure should be used _unless_ it is discussed in the text;
      + No text should claim a result _unless_ there is an associated future.


      Your report should be a [technical report](https://www.cg.tuwien.ac.at/resources/HowToWriteAScientificPaper.html).
      For a list of sections of those reports, plus some tips, see

      + [here](http://cs.stanford.edu/people/widom/paper-writing.html)
      + and [here](https://www.cg.tuwien.ac.at/resources/HowToWriteAScientificPaper.html)
      + and [here](http://www.dgp.toronto.edu/~hertzman/advice/writing-technical-papers.pdf)

      Two key parts of the reports are "threats to validity" and "future work". For notes on those sections, please see:

      + _[threats to validity](http://www.robertfeldt.net/publications/feldt_2010_validity_threats_in_ese_initial_survey.pdf)_
      + _[future work](https://guidetogradschoolsurvival.wordpress.com/2011/04/15/how-to-write-future-workconclusions-2/)_.
      Note that the _better_ your future work section, the _better_ your mark. In future work,
            we really can see what your learned from the experience of this work-- what strange quirks
                you have observered and what insights those quirks may bring.

## Code7: early Termination

Can you learn when enough is enough.

If the code runs in "eras" of, say, 100 evals per era, how to test in era X that there has been no future improvement expected?

- Type1: just compare median performance scores (design challenge: what performance score to use?)
- Type2: Use effect size tests to just if the performance scores are not changing (design challenge: what threshold should you use for a "small effect"?)
- Type2: Use effect size + hypothesis test (bootstrap) to judge no improvement (design challenge: how many bootstraps to use?)

For DE and MWS and SA, code up the Type1,Type2, Type3 comparison operators and use them to:

+ Find the final era computed by DE, MWS, SA (with early termination)
+ Computer the cdom _loss_ numbers between era0 the final era
     + Important implementation note: repeat the above with 20 different baseline populations. For each baseline, run DE,MWS,SA.

     Apply the above for [DTLZ7](http://e-collection.library.ethz.ch/eserv/eth:24696/eth-24696-01.pdf)
     with 2 objectives 10 decisions.

ALso comemnt on the runtime implications (if any) of using  bootstrap.

## Code8: Implemment NSGA-II

Extend the GA given to you in class such that it implements two variants of the NSGA-II algorithm described in class (coming next week):

- Bdom with cubiod sorting
- Cdom

On
20 repeats of  [DTLZ1,3,5,7](http://e-collection.library.ethz.ch/eserv/eth:24696/eth-24696-01.pdf)
with 2,4,6,8 objectives and 10,20,40 decisions, 
using the `stats.py` file given to you in class to comment on the value of cdom vs bdcom+cuboid.

The usual design challenges are left to you (but explain how you addressed them in your report):

- what performance measure?
- what values for cross-over, mutation, pop size, #generations?

## Code9: Hyper parameter optimization (hard)

Use DE to tune your defaults for GAs.

Create at least three options for mutation, crossover, select, number of candidates, number of generations.
See if  standard DE (default control settings) can improve on the scores seen in COde9.

Using the statistical machinery discussed in class (Scott-Knott, a12, bootstrap) to decide in any of
tuned or untuned GAs are best for
[DTLZ1,3,5,7](http://e-collection.library.ethz.ch/eserv/eth:24696/eth-24696-01.pdf)
with 2,4,6,8 objectives and 10,20,40 decisions. Remember to repeat your runs of tuned vs untuned using the
same baseline populations.
Use the `stats.py` file given to you in class to comment on the value of cdom vs bdcom+cuboid.

